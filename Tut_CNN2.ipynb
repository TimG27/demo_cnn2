{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tut_CNN2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPG_1qUw8Fxb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device (\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "RL5f7ds5_dJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "#learning_rate = 0.05\n",
        "#num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Architecture\n",
        "#num_classes = 10"
      ],
      "metadata": {
        "id": "a933uWHU_oAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget --no-check-certificate \"https://github.com/TimG27/demo_cnn/blob/main/tr_dataset.zip\""
      ],
      "metadata": {
        "id": "yu_Rl2-mHAaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import zipfile\n",
        "\n",
        "#import tarfile\n",
        "#tar = tarfile.open('tr_dataset.zip', 'r:gz')\n",
        "#tar.extractall()\n",
        "#tar.close()\n",
        "\n",
        "#zip_ref = zipfile.ZipFile('tr_dataset.zip', 'r') #Opens the zip file in read mode\n",
        "#zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "#zip_ref.close()"
      ],
      "metadata": {
        "id": "IgPeq8BqJFoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget --no-check-certificate \\\n",
        " #   \"https://github.com/TimG27/demo_cnn/archive/refs/heads/main.zip\" \\\n",
        "  #  -O \"/ptmp/tr_dataset.zip\"\n",
        "\n",
        "#import zipfile\n",
        "\n",
        "#zip_ref = zipfile.ZipFile('/ptmp/tr_dataset.zip', 'r') #Opens the zip file in read mode\n",
        "#zip_ref.extractall('/ptmp') #Extracts the files into the /tmp folder\n",
        "#zip_ref.close()"
      ],
      "metadata": {
        "id": "Hy1Kgr5PQeuB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -cq https://github.com/TimG27/demo_cnn/raw/main/tr_dataset.zip"
      ],
      "metadata": {
        "id": "-qQ9gJWOgk2D"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile('tr_dataset.zip', 'r') \n",
        "zip_ref.extractall() \n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "YrIEXwgHgsb_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "transformer = transforms.Compose([\n",
        "                                  transforms.Resize((256,256)),\n",
        "                                  transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "-R9VDDYeoD92"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(torchvision.datasets.ImageFolder(train_path, transform = transformer), \n",
        "                          batch_size=batch_size, \n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader (torchvision.datasets.ImageFolder(test_path, transform = transformer),\n",
        "                          batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "m4nwTZqqhMIj"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "root = pathlib.Path (train_path)\n",
        "classes = sorted ([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "metadata": {
        "id": "nKAHaDKOj987"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4NVUlQ9kSvT",
        "outputId": "d2126512-afaa-4ea6-963a-af6efea7105d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['retroflex-rectum']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in test_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yATEluLUl0HN",
        "outputId": "29b75c87-1a0b-4797-c47f-35d7a434dc4c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([2, 3, 256, 256])\n",
            "Image label dimensions: torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class FireModule (nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes, expand1x1_planes, expand3x3_planes):\n",
        "        super(FireModule, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)"
      ],
      "metadata": {
        "id": "ds8n9ZGopCXx"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "\n",
        "class FireBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(FireBlock, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                \n",
        "                FireModule(96, 16, 64, 64),\n",
        "                FireModule(128, 16, 64, 64),\n",
        "\n",
        "                nn.Conv2d(128, self.num_classes, kernel_size=7),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #x = self.classifier(x)\n",
        "        return torch.flatten(x, 1)\n",
        "        #return x;\n",
        "\n",
        "\n",
        "'''\n",
        "                FireModule(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                FireModule(256, 32, 128, 128),\n",
        "                FireModule(256, 48, 192, 192),\n",
        "                FireModule(384, 48, 192, 192),\n",
        "                FireModule(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                FireModule(512, 64, 256, 256),\n",
        "            )\n",
        "\n",
        "        # Final convolution is initialized differently from the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "uqy3eWvIuaPG",
        "outputId": "accf5059-f7d0-4232-f6b6-9a3a6dea2668"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n                FireModule(128, 32, 128, 128),\\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\\n                FireModule(256, 32, 128, 128),\\n                FireModule(256, 48, 192, 192),\\n                FireModule(384, 48, 192, 192),\\n                FireModule(384, 64, 256, 256),\\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\\n                FireModule(512, 64, 256, 256),\\n            )\\n\\n        # Final convolution is initialized differently from the rest\\n        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\\n        self.classifier = nn.Sequential(\\n            nn.Dropout(p=0.5),\\n            final_conv,\\n            nn.ReLU(inplace=True),\\n            nn.AdaptiveAvgPool2d((1, 1))\\n        )\\n\\n        for m in self.modules():\\n            if isinstance(m, nn.Conv2d):\\n                if m is final_conv:\\n                    init.normal_(m.weight, mean=0.0, std=0.01)\\n                else:\\n                    init.kaiming_uniform_(m.weight)\\n                if m.bias is not None:\\n                    init.constant_(m.bias, 0)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FireBlock (num_classes = 1).to(device)"
      ],
      "metadata": {
        "id": "zSga6k73wq4t"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "\n",
        "#Optmizer and loss function\n",
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "K_0J-VytxTps"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "M2PpWy-jx8Gw"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the size of training and testing images\n",
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
      ],
      "metadata": {
        "id": "04ThUoaHyLJP"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_count,test_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHAtHHQsyPIX",
        "outputId": "7ad83989-1a59-4255-f6cf-9d5c5504fa1e"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRthZaEYyTnS",
        "outputId": "c7290570-fcd6-48fc-c68c-33b70385ac9d"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train Loss: tensor(6.6658) Train Accuracy: 0.0 Test Accuracy: 0.5\n",
            "Epoch: 1 Train Loss: tensor(6.6579) Train Accuracy: 0.3333333333333333 Test Accuracy: 1.0\n",
            "Epoch: 2 Train Loss: tensor(6.6293) Train Accuracy: 0.8333333333333334 Test Accuracy: 1.0\n",
            "Epoch: 3 Train Loss: tensor(6.5806) Train Accuracy: 0.8333333333333334 Test Accuracy: 1.0\n",
            "Epoch: 4 Train Loss: tensor(6.5043) Train Accuracy: 0.8333333333333334 Test Accuracy: 1.0\n",
            "Epoch: 5 Train Loss: tensor(6.4000) Train Accuracy: 0.8333333333333334 Test Accuracy: 1.0\n",
            "Epoch: 6 Train Loss: tensor(6.2723) Train Accuracy: 0.8333333333333334 Test Accuracy: 1.0\n",
            "Epoch: 7 Train Loss: tensor(6.1037) Train Accuracy: 0.8333333333333334 Test Accuracy: 1.0\n",
            "Epoch: 8 Train Loss: tensor(5.8942) Train Accuracy: 1.0 Test Accuracy: 1.0\n",
            "Epoch: 9 Train Loss: tensor(5.6467) Train Accuracy: 1.0 Test Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}